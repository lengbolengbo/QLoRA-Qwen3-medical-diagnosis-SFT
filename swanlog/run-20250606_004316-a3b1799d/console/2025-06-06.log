swanlab: \ Creating experiment...                                                                                                    swanlab: Tracking run with swanlab version 0.4.3
swanlab: Run data will be saved locally in D:\Projects\Qwen3-Medical-SFT\swanlog\run-20250606_004316-a3b1799d
swanlab: üëã Hi blackswanNo1, welcome to swanlab!
swanlab: Syncing run qwen3-1.7B-QLoRA-v2 to the cloud
swanlab: üåü Run `swanlab watch D:\Projects\Qwen3-Medical-SFT\swanlog` to view SwanLab Experiment Dashboard locally
swanlab: üè† View project at https://swanlab.cn/@blackswanNo1/qwen3-sft-medical
swanlab: üöÄ View run at https://swanlab.cn/@blackswanNo1/qwen3-sft-medical/runs/museav32g60ctwd1457yu
{'loss': 1.9088, 'grad_norm': 1.6312940120697021, 'learning_rate': 4.390243902439025e-05, 'epoch': 0.07}
{'loss': 1.5855, 'grad_norm': 1.1942592859268188, 'learning_rate': 9.26829268292683e-05, 'epoch': 0.15}
{'loss': 1.4297, 'grad_norm': 0.8141695857048035, 'learning_rate': 0.00014146341463414634, 'epoch': 0.22}
{'loss': 1.3544, 'grad_norm': 0.797197699546814, 'learning_rate': 0.0001902439024390244, 'epoch': 0.3}
{'loss': 1.3404, 'grad_norm': 0.7152915596961975, 'learning_rate': 0.00019976560525993014, 'epoch': 0.37}
{'loss': 1.2885, 'grad_norm': 0.6228357553482056, 'learning_rate': 0.0001988152595435372, 'epoch': 0.44}
{'loss': 1.2685, 'grad_norm': 0.6739558577537537, 'learning_rate': 0.00019714126740684676, 'epoch': 0.52}
{'loss': 1.2641, 'grad_norm': 0.6437897682189941, 'learning_rate': 0.0001947558878716225, 'epoch': 0.59}
{'loss': 1.2622, 'grad_norm': 0.6401139497756958, 'learning_rate': 0.0001916765896099065, 'epoch': 0.66}
{'loss': 1.2358, 'grad_norm': 0.5611584782600403, 'learning_rate': 0.0001879259230169961, 'epoch': 0.74}
swanlab: Step 100 on key train/epoch already exists, ignored.
swanlab: Step 100 on key train/global_step already exists, ignored.
{'eval_loss': 1.2387741804122925, 'eval_runtime': 57.8279, 'eval_samples_per_second': 4.168, 'eval_steps_per_second': 4.168, 'epoch': 0.74}
{'loss': 1.2283, 'grad_norm': 0.60307377576828, 'learning_rate': 0.0001835313550698159, 'epoch': 0.81}
{'loss': 1.227, 'grad_norm': 0.5657212734222412, 'learning_rate': 0.00017852506818005447, 'epoch': 0.89}
{'loss': 1.2342, 'grad_norm': 0.518801212310791, 'learning_rate': 0.0001729437245151087, 'epoch': 0.96}
{'loss': 1.158, 'grad_norm': 0.5674900412559509, 'learning_rate': 0.0001668281975127679, 'epoch': 1.03}
{'loss': 1.039, 'grad_norm': 0.5780344605445862, 'learning_rate': 0.0001602232725558153, 'epoch': 1.1}
{'loss': 1.0407, 'grad_norm': 0.5974119901657104, 'learning_rate': 0.00015317731899857436, 'epoch': 1.18}
{'loss': 1.036, 'grad_norm': 0.5934687256813049, 'learning_rate': 0.00014574193594722395, 'epoch': 1.25}
{'loss': 1.0492, 'grad_norm': 0.5549173355102539, 'learning_rate': 0.00013797157438791245, 'epoch': 1.32}
{'loss': 1.0459, 'grad_norm': 0.5407813787460327, 'learning_rate': 0.00012992313842991187, 'epoch': 1.4}
{'loss': 1.0384, 'grad_norm': 0.5532659292221069, 'learning_rate': 0.00012165556858399873, 'epoch': 1.47}
swanlab: Step 200 on key train/epoch already exists, ignored.
swanlab: Step 200 on key train/global_step already exists, ignored.
{'eval_loss': 1.1916160583496094, 'eval_runtime': 57.76, 'eval_samples_per_second': 4.172, 'eval_steps_per_second': 4.172, 'epoch': 1.47}
{'loss': 1.0245, 'grad_norm': 0.5254305601119995, 'learning_rate': 0.00011322941012780708, 'epoch': 1.55}
{'loss': 1.0101, 'grad_norm': 0.5422964692115784, 'learning_rate': 0.00010470636971911276, 'epoch': 1.62}
{'loss': 1.0257, 'grad_norm': 0.5877465605735779, 'learning_rate': 9.614886350406864e-05, 'epoch': 1.69}
{'loss': 1.0201, 'grad_norm': 0.5759537816047668, 'learning_rate': 8.761956002969672e-05, 'epoch': 1.77}
{'loss': 1.0264, 'grad_norm': 0.5648661255836487, 'learning_rate': 7.918092130799151e-05, 'epoch': 1.84}
{'loss': 1.0363, 'grad_norm': 0.530057966709137, 'learning_rate': 7.089474539252657e-05, 'epoch': 1.92}
{'loss': 1.0253, 'grad_norm': 0.5515525341033936, 'learning_rate': 6.282171381737741e-05, 'epoch': 1.99}
{'loss': 0.9046, 'grad_norm': 0.5165097713470459, 'learning_rate': 5.502094721256916e-05, 'epoch': 2.06}
{'loss': 0.8751, 'grad_norm': 0.5443918108940125, 'learning_rate': 4.754957235037586e-05, 'epoch': 2.13}
{'loss': 0.8942, 'grad_norm': 0.5675021409988403, 'learning_rate': 4.046230379308982e-05, 'epoch': 2.21}
swanlab: Step 300 on key train/epoch already exists, ignored.
swanlab: Step 300 on key train/global_step already exists, ignored.
{'eval_loss': 1.180047869682312, 'eval_runtime': 57.7985, 'eval_samples_per_second': 4.17, 'eval_steps_per_second': 4.17, 'epoch': 2.21}
{'loss': 0.8798, 'grad_norm': 0.6021177172660828, 'learning_rate': 3.3811043205948366e-05, 'epoch': 2.28}
{'loss': 0.8648, 'grad_norm': 0.5348597168922424, 'learning_rate': 2.7644499269539724e-05, 'epoch': 2.35}
{'loss': 0.8695, 'grad_norm': 0.5521289706230164, 'learning_rate': 2.2007830975155363e-05, 'epoch': 2.43}
{'loss': 0.8923, 'grad_norm': 0.5301797389984131, 'learning_rate': 1.694231691531709e-05, 'epoch': 2.5}
{'loss': 0.884, 'grad_norm': 0.5644136667251587, 'learning_rate': 1.2485052991339174e-05, 'epoch': 2.58}
{'loss': 0.8672, 'grad_norm': 0.5276333689689636, 'learning_rate': 8.668680751680835e-06, 'epoch': 2.65}
{'loss': 0.8885, 'grad_norm': 0.5447303652763367, 'learning_rate': 5.521148350529137e-06, 'epoch': 2.72}
{'loss': 0.8745, 'grad_norm': 0.564721941947937, 'learning_rate': 3.065505877165675e-06, 'epoch': 2.8}
{'loss': 0.8658, 'grad_norm': 0.5559476017951965, 'learning_rate': 1.319736554966955e-06, 'epoch': 2.87}
{'loss': 0.8717, 'grad_norm': 0.5531328320503235, 'learning_rate': 2.9662504620588947e-07, 'epoch': 2.94}
swanlab: Step 400 on key train/epoch already exists, ignored.
swanlab: Step 400 on key train/global_step already exists, ignored.
{'eval_loss': 1.1771032810211182, 'eval_runtime': 57.7682, 'eval_samples_per_second': 4.172, 'eval_steps_per_second': 4.172, 'epoch': 2.94}
